nohup: ignoring input
2022-06-11 11:33:54.042308: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so
Missing key: 'TWIST' in 'tpu-env' (yaml) instance metadata.
2022-06-11 11:33:55.657417: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-11 11:33:59.033080: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x6b19980 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:
2022-06-11 11:33:59.033130: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): TPU, 2a886c8
2022-06-11 11:33:59.033141: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (1): TPU, 2a886c8
2022-06-11 11:33:59.033148: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (2): TPU, 2a886c8
2022-06-11 11:33:59.033155: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (3): TPU, 2a886c8
2022-06-11 11:33:59.033162: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (4): TPU, 2a886c8
2022-06-11 11:33:59.033169: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (5): TPU, 2a886c8
2022-06-11 11:33:59.033176: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (6): TPU, 2a886c8
2022-06-11 11:33:59.033182: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (7): TPU, 2a886c8
WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.
2022-06-11 11:34:04.214933: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-06-11 11:34:04.235758: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-11 11:34:04.250797: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. RandomUniform
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 550, 6)]     0           []                               
                                                                                                  
 conv1d (Conv1D)                (None, 550, 64)      1216        ['input_1[0][0]']                
                                                                                                  
 concatenate (Concatenate)      (None, 550, 70)      0           ['conv1d[0][0]',                 
                                                                  'input_1[0][0]']                
                                                                                                  
 dense (Dense)                  (None, 550, 32)      2272        ['concatenate[0][0]']            
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 550, 32)      0           ['dense[0][0]']                  
                                                                                                  
 conv1d_1 (Conv1D)              (None, 550, 128)     20608       ['leaky_re_lu[0][0]']            
                                                                                                  
 concatenate_1 (Concatenate)    (None, 550, 160)     0           ['conv1d_1[0][0]',               
                                                                  'leaky_re_lu[0][0]']            
                                                                                                  
 dense_1 (Dense)                (None, 550, 64)      10304       ['concatenate_1[0][0]']          
                                                                                                  
 conv1d_2 (Conv1D)              (None, 550, 128)     41088       ['dense_1[0][0]']                
                                                                                                  
 concatenate_2 (Concatenate)    (None, 550, 192)     0           ['conv1d_2[0][0]',               
                                                                  'dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 550, 128)     24704       ['concatenate_2[0][0]']          
                                                                                                  
 conv1d_3 (Conv1D)              (None, 550, 128)     82048       ['dense_2[0][0]']                
                                                                                                  
 add (Add)                      (None, 550, 128)     0           ['conv1d_3[0][0]',               
                                                                  'dense_2[0][0]']                
                                                                                                  
 conv1d_4 (Conv1D)              (None, 550, 128)     82048       ['add[0][0]']                    
                                                                                                  
 add_1 (Add)                    (None, 550, 128)     0           ['conv1d_4[0][0]',               
                                                                  'add[0][0]']                    
                                                                                                  
 conv1d_5 (Conv1D)              (None, 550, 128)     82048       ['add_1[0][0]']                  
                                                                                                  
 add_2 (Add)                    (None, 550, 128)     0           ['conv1d_5[0][0]',               
                                                                  'add_1[0][0]']                  
                                                                                                  
 conv1d_6 (Conv1D)              (None, 550, 128)     82048       ['add_2[0][0]']                  
                                                                                                  
 add_3 (Add)                    (None, 550, 128)     0           ['conv1d_6[0][0]',               
                                                                  'add_2[0][0]']                  
                                                                                                  
 conv1d_7 (Conv1D)              (None, 550, 128)     82048       ['add_3[0][0]']                  
                                                                                                  
 add_4 (Add)                    (None, 550, 128)     0           ['conv1d_7[0][0]',               
                                                                  'add_3[0][0]']                  
                                                                                                  
 dense_3 (Dense)                (None, 550, 32)      4128        ['add_4[0][0]']                  
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 550, 32)      0           ['dense_3[0][0]']                
                                                                                                  
 dense_4 (Dense)                (None, 550, 16)      528         ['leaky_re_lu_1[0][0]']          
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 550, 16)      0           ['dense_4[0][0]']                
                                                                                                  
 tf.__operators__.getitem (Slic  (None, 6)           0           ['input_1[0][0]']                
 ingOpLambda)                                                                                     
                                                                                                  
 input_2 (InputLayer)           [(None, 2)]          0           []                               
                                                                                                  
 flatten (Flatten)              (None, 8800)         0           ['leaky_re_lu_2[0][0]']          
                                                                                                  
 reshape (Reshape)              (None, 6)            0           ['tf.__operators__.getitem[0][0]'
                                                                 ]                                
                                                                                                  
 concatenate_3 (Concatenate)    (None, 8808)         0           ['input_2[0][0]',                
                                                                  'flatten[0][0]',                
                                                                  'reshape[0][0]']                
                                                                                                  
 dense_5 (Dense)                (None, 512)          4510208     ['concatenate_3[0][0]']          
                                                                                                  
 leaky_re_lu_3 (LeakyReLU)      (None, 512)          0           ['dense_5[0][0]']                
                                                                                                  
 dense_6 (Dense)                (None, 512)          262656      ['leaky_re_lu_3[0][0]']          
                                                                                                  
 leaky_re_lu_4 (LeakyReLU)      (None, 512)          0           ['dense_6[0][0]']                
                                                                                                  
 dense_7 (Dense)                (None, 512)          262656      ['leaky_re_lu_4[0][0]']          
                                                                                                  
 leaky_re_lu_5 (LeakyReLU)      (None, 512)          0           ['dense_7[0][0]']                
                                                                                                  
 dense_8 (Dense)                (None, 512)          262656      ['leaky_re_lu_5[0][0]']          
                                                                                                  
 leaky_re_lu_6 (LeakyReLU)      (None, 512)          0           ['dense_8[0][0]']                
                                                                                                  
 dense_9 (Dense)                (None, 2)            1024        ['leaky_re_lu_6[0][0]']          
                                                                                                  
==================================================================================================
Total params: 5,814,288
Trainable params: 5,814,288
Non-trainable params: 0
__________________________________________________________________________________________________
2022-06-11 11:35:27.107846: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:15898058692170133547
2022-06-11 11:35:27.123402: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:35:27.144050: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:35:27.175337: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(12977028932347916115), session_name()
2022-06-11 11:35:27.934105: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 12977028932347916115 with session name  took 758.700963ms and succeeded
2022-06-11 11:35:27.938157: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(12977028932347916115), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_15898058692170133547", property.function_library_fingerprint = 12471264065059247924, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-11 11:35:27.938200: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 12977028932347916115 with session_name  cache is 1 entries (3440059 bytes),  marked for eviction 0 entries (0 bytes).
2022-06-11 11:41:52.125001: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:15892338235893465589
2022-06-11 11:41:52.144265: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:41:52.168846: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:41:52.206935: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(2271604716635649573), session_name()
2022-06-11 11:41:52.853241: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 2271604716635649573 with session name  took 646.208984ms and succeeded
2022-06-11 11:41:52.855785: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(2271604716635649573), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_15892338235893465589", property.function_library_fingerprint = 1687833938808460472, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-11 11:41:52.855829: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 2271604716635649573 with session_name  cache is 2 entries (6432623 bytes),  marked for eviction 0 entries (0 bytes).
2022-06-11 11:41:58.020537: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:4760207328911789435
2022-06-11 11:41:58.229964: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:41:58.549791: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-11 11:41:58.963387: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(3699435369752795500), session_name()
2022-06-11 11:42:04.447398: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 3699435369752795500 with session name  took 5.483913038s and succeeded
2022-06-11 11:42:04.465953: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(3699435369752795500), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_4760207328911789435", property.function_library_fingerprint = 12893515161088349077, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-11 11:42:04.466003: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 3699435369752795500 with session_name  cache is 3 entries (32837009 bytes),  marked for eviction 0 entries (0 bytes).
https://symbolize.stripped_domain/r/?trace=5f0029,7fcb9fa2b08f,909b3f&map= 
*** SIGTERM received by PID 53931 (TID 53931) on cpu 5 from PID 53726; stack trace: ***
PC: @           0x5f0029  (unknown)  (unknown)
    @     0x7fcae6241ed3        992  (unknown)
    @     0x7fcb9fa2b090  (unknown)  (unknown)
    @           0x909b40  (unknown)  (unknown)
https://symbolize.stripped_domain/r/?trace=5f0029,7fcae6241ed2,7fcb9fa2b08f,909b3f&map=8654562a659840069c67d57e08f7541c:7fcad1f3b000-7fcae65b9b10 
E0611 12:44:44.465797   53931 coredump_hook.cc:320] RAW: Remote crash gathering disabled for SIGTERM.
E0611 12:44:44.998881   53931 process_state.cc:765] RAW: Raising signal 15 with default behavior
