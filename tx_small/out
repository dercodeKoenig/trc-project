nohup: ignoring input
2022-06-05 23:06:03.810911: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so
Missing key: 'TWIST' in 'tpu-env' (yaml) instance metadata.
2022-06-05 23:06:05.452645: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-05 23:06:09.029547: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x68e3980 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:
2022-06-05 23:06:09.029591: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): TPU, 2a886c8
2022-06-05 23:06:09.029600: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (1): TPU, 2a886c8
2022-06-05 23:06:09.029607: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (2): TPU, 2a886c8
2022-06-05 23:06:09.029614: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (3): TPU, 2a886c8
2022-06-05 23:06:09.029621: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (4): TPU, 2a886c8
2022-06-05 23:06:09.029627: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (5): TPU, 2a886c8
2022-06-05 23:06:09.029634: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (6): TPU, 2a886c8
2022-06-05 23:06:09.029641: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (7): TPU, 2a886c8
WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.
2022-06-05 23:06:16.516147: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-06-05 23:06:16.537761: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-05 23:06:16.552480: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. RandomUniform
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 550, 6)]     0           []                               
                                                                                                  
 dense (Dense)                  (None, 550, 16)      112         ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 550, 16)      272         ['dense[0][0]']                  
                                                                                                  
 conv1d (Conv1D)                (None, 550, 64)      3136        ['dense_1[0][0]']                
                                                                                                  
 concatenate (Concatenate)      (None, 550, 80)      0           ['conv1d[0][0]',                 
                                                                  'dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 550, 32)      2592        ['concatenate[0][0]']            
                                                                                                  
 conv1d_1 (Conv1D)              (None, 550, 512)     344576      ['dense_2[0][0]']                
                                                                                                  
 concatenate_1 (Concatenate)    (None, 550, 544)     0           ['conv1d_1[0][0]',               
                                                                  'dense_2[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 550, 512)     279040      ['concatenate_1[0][0]']          
                                                                                                  
 dense_4 (Dense)                (None, 550, 256)     131328      ['dense_3[0][0]']                
                                                                                                  
 layer_normalization (LayerNorm  (None, 550, 256)    512         ['dense_4[0][0]']                
 alization)                                                                                       
                                                                                                  
 positions (Positions)          (None, 550, 256)     0           ['layer_normalization[0][0]']    
                                                                                                  
 transformer_block (Transformer  (None, 550, 256)    2236160     ['positions[0][0]',              
 Block)                                                           'positions[0][0]']              
                                                                                                  
 transformer_block_1 (Transform  (None, 550, 256)    2236160     ['transformer_block[0][0]',      
 erBlock)                                                         'transformer_block[0][0]']      
                                                                                                  
 transformer_block_2 (Transform  (None, 550, 256)    2236160     ['transformer_block_1[0][0]',    
 erBlock)                                                         'transformer_block_1[0][0]']    
                                                                                                  
 transformer_block_3 (Transform  (None, 550, 256)    2236160     ['transformer_block_2[0][0]',    
 erBlock)                                                         'transformer_block_2[0][0]']    
                                                                                                  
 lambda (Lambda)                (None, 256)          0           ['transformer_block_3[0][0]']    
                                                                                                  
 reshape (Reshape)              (None, 1, 256)       0           ['lambda[0][0]']                 
                                                                                                  
 transformer_block_4 (Transform  (None, 1, 256)      2236160     ['reshape[0][0]',                
 erBlock)                                                         'transformer_block_3[0][0]']    
                                                                                                  
 input_2 (InputLayer)           [(None, 2)]          0           []                               
                                                                                                  
 flatten (Flatten)              (None, 256)          0           ['transformer_block_4[0][0]']    
                                                                                                  
 concatenate_2 (Concatenate)    (None, 258)          0           ['input_2[0][0]',                
                                                                  'flatten[0][0]']                
                                                                                                  
 dense_15 (Dense)               (None, 512)          132608      ['concatenate_2[0][0]']          
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense_15[0][0]']               
                                                                                                  
 dense_16 (Dense)               (None, 512)          262656      ['leaky_re_lu[0][0]']            
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 512)          0           ['dense_16[0][0]']               
                                                                                                  
 dense_17 (Dense)               (None, 512)          262656      ['leaky_re_lu_1[0][0]']          
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 512)          0           ['dense_17[0][0]']               
                                                                                                  
 dense_18 (Dense)               (None, 3)            1536        ['leaky_re_lu_2[0][0]']          
                                                                                                  
==================================================================================================
Total params: 12,601,824
Trainable params: 12,601,824
Non-trainable params: 0
__________________________________________________________________________________________________
loading weights...
warmup...
2022-06-05 23:07:39.931160: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:13793478483563359504
2022-06-05 23:07:39.975209: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:07:40.026771: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:07:40.101585: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(16750561978805250095), session_name()
2022-06-05 23:07:42.578794: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 16750561978805250095 with session name  took 2.477109736s and succeeded
2022-06-05 23:07:42.590191: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(16750561978805250095), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_13793478483563359504", property.function_library_fingerprint = 7955759564443233598, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 23:07:42.590242: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 16750561978805250095 with session_name  cache is 1 entries (16463402 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.0
q: 0.0
reward sum -154.61311373020973
l/s 0.34618049540966567
t 74.74195957183838
-----------
/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
training...
2022-06-05 23:14:39.183713: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:10613540162402947233
2022-06-05 23:14:39.232945: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:14:39.290461: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:14:39.378413: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(12831377196918434308), session_name()
2022-06-05 23:14:41.809313: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 12831377196918434308 with session name  took 2.430797662s and succeeded
2022-06-05 23:14:41.816588: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(12831377196918434308), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_10613540162402947233", property.function_library_fingerprint = 17155160153533551208, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 23:14:41.816629: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 12831377196918434308 with session_name  cache is 2 entries (31784919 bytes),  marked for eviction 0 entries (0 bytes).
2022-06-05 23:14:50.680180: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:7297098667890567285
2022-06-05 23:14:51.094906: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:14:51.503395: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 23:14:52.095011: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(10344332891224803048), session_name()
2022-06-05 23:15:09.631067: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 10344332891224803048 with session name  took 17.535912108s and succeeded
2022-06-05 23:15:09.678415: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(10344332891224803048), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_7297098667890567285", property.function_library_fingerprint = 12965129548869501772, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 23:15:09.678471: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 10344332891224803048 with session_name  cache is 3 entries (154745369 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.030116966900571925
q: 0.00477262764993975
reward sum 14.008668702029674
l/s 0.38730277986476336
t 280.01837730407715
-----------
-----------
l: 0.03169757967447957
q: 0.004474256341050922
reward sum 26.408043294209907
l/s 0.19020891799189274
t 279.9654722213745
-----------
-----------
l: 0.03271957002277543
q: 0.004128965968320599
reward sum 21.444135295734046
l/s -0.3544891640866873
t 284.3147277832031
-----------
-----------
l: 0.03496134516782323
q: 0.003430834454951588
reward sum 14.993092179671025
l/s -0.5402155887230514
t 280.78715801239014
-----------
-----------
l: 0.03548567698219047
q: 0.003594644682630564
reward sum 21.620191332192597
l/s 0.3934720229555237
t 282.9707145690918
-----------
-----------
l: 0.03419772191541272
q: 0.0036918246388557858
reward sum -13.029435963483072
l/s 0.29087511678604794
t 283.0202102661133
-----------
-----------
l: 0.03895490486338808
q: 0.0032322656352737505
reward sum -15.802890290146333
l/s 0.5033979360684622
t 281.71684741973877
-----------
-----------
l: 0.03722019107057251
q: 0.003885656764972615
reward sum -18.43415853353055
l/s -0.5799112097669257
t 282.0531129837036
-----------
-----------
l: 0.03868153590425076
q: 0.0034700545662929867
reward sum -33.49892978793697
l/s -0.057335907335907335
t 282.53321647644043
-----------
-----------
l: 0.04036008210949477
q: 0.003881397445832851
reward sum -34.568369769128736
l/s 0.22905620360551432
t 283.1275463104248
-----------
-----------
l: 0.04235327408796311
q: 0.00427174710142305
reward sum -13.118542548864633
l/s -0.07701652089407192
t 283.92064571380615
-----------
-----------
l: 0.04552852389781299
q: 0.004195750694620542
reward sum -76.91196334085956
l/s 0.33586586324338485
t 283.61337184906006
-----------
-----------
l: 0.044864347289981274
q: 0.004669504158085362
reward sum -49.33227444237103
l/s 0.35418611889200124
t 284.71696376800537
-----------
-----------
l: 0.04577836889291632
q: 0.0047322610903879165
reward sum -20.217090369685152
l/s -0.21347989586346544
t 285.12415885925293
-----------
-----------
l: 0.045864581322523856
q: 0.004798235792518713
reward sum -30.813197852358314
l/s 0.10416666666666667
t 285.5026960372925
-----------
-----------
l: 0.04711471914413653
q: 0.005173523178157708
reward sum 24.306789944712175
l/s 0.0705942974922707
t 287.314248085022
-----------
-----------
l: 0.04709314741691381
q: 0.005943924641656281
reward sum -42.13275607659991
l/s -0.009368111682586333
t 285.07869243621826
-----------
