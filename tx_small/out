nohup: ignoring input
2022-06-05 01:33:36.386147: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so
Missing key: 'TWIST' in 'tpu-env' (yaml) instance metadata.
2022-06-05 01:33:38.043661: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-05 01:33:41.868717: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x647f980 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:
2022-06-05 01:33:41.868775: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): TPU, 2a886c8
2022-06-05 01:33:41.868807: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (1): TPU, 2a886c8
2022-06-05 01:33:41.868824: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (2): TPU, 2a886c8
2022-06-05 01:33:41.868836: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (3): TPU, 2a886c8
2022-06-05 01:33:41.868846: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (4): TPU, 2a886c8
2022-06-05 01:33:41.868856: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (5): TPU, 2a886c8
2022-06-05 01:33:41.868866: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (6): TPU, 2a886c8
2022-06-05 01:33:41.868877: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (7): TPU, 2a886c8
WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.
2022-06-05 01:33:49.129483: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-06-05 01:33:49.150106: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-05 01:33:49.164559: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. RandomUniform
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 550, 6)]     0           []                               
                                                                                                  
 dense (Dense)                  (None, 550, 16)      112         ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 550, 16)      272         ['dense[0][0]']                  
                                                                                                  
 conv1d (Conv1D)                (None, 550, 64)      3136        ['dense_1[0][0]']                
                                                                                                  
 concatenate (Concatenate)      (None, 550, 80)      0           ['conv1d[0][0]',                 
                                                                  'dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 550, 32)      2592        ['concatenate[0][0]']            
                                                                                                  
 conv1d_1 (Conv1D)              (None, 550, 512)     344576      ['dense_2[0][0]']                
                                                                                                  
 concatenate_1 (Concatenate)    (None, 550, 544)     0           ['conv1d_1[0][0]',               
                                                                  'dense_2[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 550, 512)     279040      ['concatenate_1[0][0]']          
                                                                                                  
 dense_4 (Dense)                (None, 550, 256)     131328      ['dense_3[0][0]']                
                                                                                                  
 layer_normalization (LayerNorm  (None, 550, 256)    512         ['dense_4[0][0]']                
 alization)                                                                                       
                                                                                                  
 positions (Positions)          (None, 550, 256)     0           ['layer_normalization[0][0]']    
                                                                                                  
 transformer_block (Transformer  (None, 550, 256)    2236160     ['positions[0][0]',              
 Block)                                                           'positions[0][0]']              
                                                                                                  
 transformer_block_1 (Transform  (None, 550, 256)    2236160     ['transformer_block[0][0]',      
 erBlock)                                                         'transformer_block[0][0]']      
                                                                                                  
 transformer_block_2 (Transform  (None, 550, 256)    2236160     ['transformer_block_1[0][0]',    
 erBlock)                                                         'transformer_block_1[0][0]']    
                                                                                                  
 transformer_block_3 (Transform  (None, 550, 256)    2236160     ['transformer_block_2[0][0]',    
 erBlock)                                                         'transformer_block_2[0][0]']    
                                                                                                  
 lambda (Lambda)                (None, 256)          0           ['transformer_block_3[0][0]']    
                                                                                                  
 reshape (Reshape)              (None, 1, 256)       0           ['lambda[0][0]']                 
                                                                                                  
 transformer_block_4 (Transform  (None, 1, 256)      2236160     ['reshape[0][0]',                
 erBlock)                                                         'transformer_block_3[0][0]']    
                                                                                                  
 input_2 (InputLayer)           [(None, 2)]          0           []                               
                                                                                                  
 flatten (Flatten)              (None, 256)          0           ['transformer_block_4[0][0]']    
                                                                                                  
 concatenate_2 (Concatenate)    (None, 258)          0           ['input_2[0][0]',                
                                                                  'flatten[0][0]']                
                                                                                                  
 dense_15 (Dense)               (None, 512)          132608      ['concatenate_2[0][0]']          
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense_15[0][0]']               
                                                                                                  
 dense_16 (Dense)               (None, 512)          262656      ['leaky_re_lu[0][0]']            
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 512)          0           ['dense_16[0][0]']               
                                                                                                  
 dense_17 (Dense)               (None, 512)          262656      ['leaky_re_lu_1[0][0]']          
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 512)          0           ['dense_17[0][0]']               
                                                                                                  
 dense_18 (Dense)               (None, 3)            1536        ['leaky_re_lu_2[0][0]']          
                                                                                                  
==================================================================================================
Total params: 12,601,824
Trainable params: 12,601,824
Non-trainable params: 0
__________________________________________________________________________________________________
loading weights...
warmup...
2022-06-05 01:35:11.678506: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:13793478483563359504
2022-06-05 01:35:11.721676: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:35:11.770942: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:35:11.844255: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(16750561978805250095), session_name()
2022-06-05 01:35:14.216616: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 16750561978805250095 with session name  took 2.372272842s and succeeded
2022-06-05 01:35:14.225387: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(16750561978805250095), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_13793478483563359504", property.function_library_fingerprint = 7955759564443233598, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 01:35:14.225438: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 16750561978805250095 with session_name  cache is 1 entries (16463402 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.0
q: 0.0
r: -0.010904528683292725
reward sum -296.21766085521176
l/s 0.32553432447410907
t 72.08013534545898
-----------
/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
training...
2022-06-05 01:42:04.933431: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:7551863438794372964
2022-06-05 01:42:04.983715: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:42:05.042186: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:42:05.136932: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(8934977074163424063), session_name()
2022-06-05 01:42:07.693552: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 8934977074163424063 with session name  took 2.556506044s and succeeded
2022-06-05 01:42:07.702020: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(8934977074163424063), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_7551863438794372964", property.function_library_fingerprint = 14208195115568480520, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 01:42:07.702066: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 8934977074163424063 with session_name  cache is 2 entries (31777495 bytes),  marked for eviction 0 entries (0 bytes).
2022-06-05 01:42:16.580950: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:15791177015978718434
2022-06-05 01:42:17.016302: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:42:17.419465: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 01:42:18.000844: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(8851895311971285803), session_name()
2022-06-05 01:42:35.080524: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 8851895311971285803 with session name  took 17.079555952s and succeeded
2022-06-05 01:42:35.125477: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(8851895311971285803), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_15791177015978718434", property.function_library_fingerprint = 11294540070068536958, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 01:42:35.125544: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 8851895311971285803 with session_name  cache is 3 entries (154791241 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.0
q: 0.0
r: -0.13212980898976762
reward sum -100.86230854640003
l/s 0.8698630136986302
t 280.1983594894409
-----------
-----------
l: 0.0
q: 0.0
r: 0.061221547190650344
reward sum -182.46480279384582
l/s 0.7221085905541094
t 282.62057304382324
-----------
-----------
l: 0.0
q: 0.0
r: 0.03807791402884453
reward sum -218.1986126996142
l/s 0.7153245831855268
t 282.0438861846924
-----------
-----------
l: 0.0
q: 0.0
r: 0.037762471853350466
reward sum -238.27181495781886
l/s 0.029692832764505118
t 280.7337999343872
-----------
-----------
l: 0.0
q: 0.0
r: -0.03539428012964363
reward sum -309.31796527515
l/s 0.6407753254102999
t 285.8711004257202
-----------
-----------
l: 0.0
q: 0.0
r: -0.0054795652705508235
reward sum -316.8134032887165
l/s 0.5592023265475696
t 286.3492012023926
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -322.8943587743574
l/s 0.34824902723735407
t 284.1026782989502
-----------
-----------
l: 0.0
q: 0.0
r: -0.0009135224105900619
reward sum -314.68840577022695
l/s 0.25324074074074077
t 284.1076612472534
-----------
-----------
l: 0.0
q: 0.0
r: -0.04237078381220061
reward sum -310.885016766771
l/s -0.01635282457879088
t 286.2353801727295
-----------
-----------
l: 0.0
q: 0.0
r: -0.0008575602603042576
reward sum -364.5816494653442
l/s 0.040342914775592535
t 284.84535217285156
-----------
-----------
l: 0.0
q: 0.0
r: -0.05580894460872532
reward sum -346.8190080656668
l/s 0.43891891891891893
t 285.85853576660156
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -372.67099424562707
l/s 0.2519294377067255
t 285.2444648742676
-----------
-----------
l: 0.0
q: 0.0
r: -0.005480825679455376
reward sum -371.5539070153117
l/s 0.3603879530372639
t 287.8908157348633
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -353.8247248932875
l/s 0.3231917336394948
t 1004.6896696090698
-----------
-----------
l: 0.0
q: 0.0
r: -0.0055397598281400895
reward sum -419.3503869724207
l/s 0.2782951289398281
t 286.5678071975708
-----------
-----------
l: 0.0
q: 0.0
r: 0.12449242958150553
reward sum -404.89905916558126
l/s 0.18818380743982493
t 284.71221923828125
-----------
-----------
l: 0.0
q: 0.0
r: -0.024664710511560273
reward sum -435.05971657973225
l/s 0.7193675889328063
t 287.3687744140625
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -398.0381882550498
l/s -0.2134071340713407
t 290.86363315582275
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -468.4203671738766
l/s 0.12973222530009235
t 287.5697135925293
-----------
-----------
l: 0.0
q: 0.0
r: -0.0715392695196565
reward sum -509.9046295092396
l/s 0.27982541222114454
t 290.24829864501953
-----------
-----------
l: 0.0
q: 0.0
r: 0.007485451543778332
reward sum -525.3394351562662
l/s 0.20665417057169636
t 290.4355525970459
-----------
-----------
l: 0.0
q: 0.0
r: 0.056680020839841916
reward sum -529.1004473855155
l/s 0.4506172839506173
t 290.0663375854492
-----------
-----------
l: 0.0
q: 0.0
r: 0.04484429381417154
reward sum -525.0112095745984
l/s 0.42615384615384616
t 288.480019569397
-----------
-----------
l: 0.0
q: 0.0
r: -0.029747501741917537
reward sum -527.1816646942366
l/s 0.18866666666666668
t 292.0035123825073
-----------
-----------
l: 0.0
q: 0.0
r: -0.06605800988036162
reward sum -551.968497918114
l/s -0.1898575020955574
t 289.49553966522217
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -563.5313391783419
l/s 0.19398293668612482
t 291.88382625579834
-----------
-----------
l: 0.0
q: 0.0
r: 0.06513585659726456
reward sum -587.9971328654146
l/s -0.24780007039774726
t 290.7417297363281
-----------
-----------
l: 0.0
q: 0.0
r: 0.024370978645545716
reward sum -559.6267266712055
l/s 0.014727540500736377
t 292.0910596847534
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -537.5334818832407
l/s 0.10897134805072804
t 289.8003578186035
-----------
-----------
l: 0.0
q: 0.0
r: 0.032863222058310715
reward sum -549.4508775627385
l/s 0.0043720190779014305
t 292.46697425842285
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -628.3528085978857
l/s -0.23007562536358347
t 292.64819622039795
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -621.6656447691299
l/s 0.11046511627906977
t 294.1042900085449
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -638.7343909549462
l/s 0.031071983428275506
t 295.49639225006104
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -645.5538325441225
l/s 0.3965721040189125
t 293.07618141174316
-----------
-----------
l: 0.0
q: 0.0
r: 0.03385561682913041
reward sum -680.64201355627
l/s 0.20317087492660013
t 297.216272354126
-----------
-----------
l: 0.0
q: 0.0
r: -0.037228942890074945
reward sum -701.2628470308732
l/s -0.009166666666666667
t 302.25937366485596
-----------
-----------
l: 0.0
q: 0.0
r: 0.0682729550106771
reward sum -658.6060892176745
l/s 0.3734793187347932
t 296.30792140960693
-----------
-----------
l: 0.0
q: 0.0
r: 0.044730437230341424
reward sum -657.3818648334212
l/s 0.39246356203341626
t 295.7261562347412
-----------
-----------
l: 0.0
q: 0.0
r: -0.02167284392726876
reward sum -680.7593681823358
l/s 0.07721202003338898
t 297.33664989471436
-----------
-----------
l: 0.0
q: 0.0
r: 0.026888973241792735
reward sum -714.3099083996196
l/s -0.024317121918720853
t 294.5579767227173
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -715.2511228782814
l/s -0.02429514097180564
t 297.26109504699707
-----------
-----------
l: 0.0
q: 0.0
r: -0.08371139847723208
reward sum -713.145912212647
l/s -0.035416666666666666
t 296.68052196502686
-----------
-----------
l: 0.0
q: 0.0
r: 0.010395635116498436
reward sum -716.4540692385552
l/s 0.39390088945362134
t 297.33030796051025
-----------
-----------
l: 0.0
q: 0.0
r: -0.003615825575665532
reward sum -701.161173148083
l/s 0.07378258730939498
t 300.40152072906494
-----------
-----------
l: 0.0
q: 0.0
r: -0.05567345667964929
reward sum -689.0517176031523
l/s 0.1822600243013366
t 302.9857635498047
-----------
-----------
l: 0.0
q: 0.0
r: 0.019786418563639996
reward sum -781.4650373063407
l/s -0.06592356687898089
t 300.1692056655884
-----------
-----------
l: 0.0
q: 0.0
r: 0.019572625990934123
reward sum -786.3936592655158
l/s 0.07387312186978297
t 302.19171047210693
-----------
-----------
l: 0.0
q: 0.0
r: -0.0008025514188885197
reward sum -744.5869775123753
l/s 0.5593132154006244
t 302.30395793914795
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -742.7407613433658
l/s 0.1354867653656348
t 302.4014711380005
-----------
-----------
l: 0.0
q: 0.0
r: 0.012606777223289178
reward sum -787.7417277906949
l/s -0.26231633535004323
t 302.71503925323486
-----------
-----------
l: 0.0
q: 0.0
r: 0.045043162265848535
reward sum -768.6954469353177
l/s -0.21943986820428335
t 305.0166368484497
-----------
-----------
l: 0.0
q: 0.0
r: -0.010932289520035554
reward sum -751.3306709346986
l/s -0.3767640301936331
t 304.48875427246094
-----------
-----------
l: 0.0
q: 0.0
r: -0.0014306552379785842
reward sum -759.253300496224
l/s -0.053480866758875055
t 306.21345043182373
-----------
-----------
l: 0.0
q: 0.0
r: 0.027977007541588828
reward sum -776.4053921162816
l/s -0.22229573271584518
t 305.3131103515625
-----------
-----------
l: 0.0
q: 0.0
r: 0.001859294741857892
reward sum -840.020650612778
l/s -0.03673163418290855
t 306.64284229278564
-----------
-----------
l: 0.0
q: 0.0
r: 0.019252430215700445
reward sum -875.6309658251865
l/s -0.037442599788060756
t 305.67030906677246
-----------
-----------
l: 0.0
q: 0.0
r: 0.016183688283197717
reward sum -875.3028797218244
l/s -0.13242151072427727
t 309.37788486480713
-----------
-----------
l: 0.0
q: 0.0
r: 0.026716717503505905
reward sum -901.6377012384598
l/s -0.3865732202139432
t 309.464955329895
-----------
-----------
l: 0.0
q: 0.0
r: 0.0
reward sum -941.591594941537
l/s -0.46324269889224573
t 311.34281158447266
-----------
-----------
l: 0.0
q: 0.0
r: 0.11131468884432105
reward sum -912.0038275140779
l/s -0.20915032679738563
t 308.5296154022217
-----------
-----------
l: 0.0
q: 0.0
r: -0.043862934154569544
reward sum -901.7686007967089
l/s -0.47466361294016607
t 310.00261306762695
-----------
-----------
l: 0.0
q: 0.0
r: 0.04936820730594138
reward sum -855.6857831472378
l/s -0.463454759106933
t 311.3752841949463
-----------
-----------
l: 0.0
q: 0.0
r: -0.0878654227389738
reward sum -811.7511686025911
l/s -0.6299487657196088
t 311.48760318756104
-----------
-----------
l: 0.0
q: 0.0
r: -0.02923403127381824
reward sum -747.031819826913
l/s -0.41467116357504213
t 308.1615447998047
-----------
-----------
l: 0.0
q: 0.0
r: -0.1288741249467671
reward sum -721.6815494909126
l/s -0.5966661917652087
t 309.43992137908936
-----------
-----------
l: 0.0
q: 0.0
r: 0.034464047987138924
reward sum -767.3685280483767
l/s -0.5668552950687147
t 307.9857349395752
-----------
-----------
l: 0.0
q: 0.0
r: -0.042292189787143775
reward sum -882.188790490994
l/s -0.48327581629944255
t 308.4329843521118
-----------
-----------
l: 0.0
q: 0.0
r: 0.019699207542639374
reward sum -844.9415536875218
l/s -0.4674303299709352
t 310.3855848312378
-----------
-----------
l: 0.0
q: 0.0
r: -0.07878494462674208
reward sum -834.0236829354412
l/s -0.4508272058823529
t 309.9741458892822
-----------
-----------
l: 0.0
q: 0.0
r: 0.055349381170572975
reward sum -779.9046154075662
l/s -0.31508704061895554
t 309.6724510192871
-----------
-----------
l: 0.0
q: 0.0
r: 0.03249781551927722
reward sum -841.0161283019631
l/s -0.26478348595374823
t 309.7709655761719
-----------
-----------
l: 0.0
q: 0.0
r: -0.034322330258564016
reward sum -837.6158903093041
l/s -0.7907091267235719
t 306.927490234375
-----------
-----------
l: 0.0
q: 0.0
r: -0.06606356870377375
reward sum -819.7961954704557
l/s -0.6366208569118836
t 306.69634342193604
-----------
-----------
l: 0.0
q: 0.0
r: 0.026222776004196188
reward sum -791.9849588033848
l/s -0.7931391394351619
t 308.88116359710693
-----------
-----------
l: 0.0
q: 0.0
r: 0.005620781374822026
reward sum -835.9427396836118
l/s -0.6249095906263561
t 307.2704076766968
-----------
-----------
l: 0.0
q: 0.0
r: -0.08047250951882678
reward sum -844.7475719228307
l/s -0.672339663203153
t 313.0221366882324
-----------
-----------
l: 0.0
q: 0.0
r: 0.12209223397362534
reward sum -877.3130426722398
l/s -0.4728525121555916
t 308.89790058135986
-----------
-----------
l: 0.0
q: 0.0
r: -0.012446498414237867
reward sum -951.7723310351656
l/s -0.6725390202441662
t 306.21283054351807
-----------
-----------
l: 0.0
q: 0.0
r: 0.05371909246882489
reward sum -929.0883636407557
l/s -0.41576354679802957
t 306.35852813720703
-----------
-----------
l: 0.0
q: 0.0
r: 0.033792069178447126
reward sum -914.8932712111564
l/s -0.7035731076633757
t 309.02719497680664
-----------
-----------
l: 0.0
q: 0.0
r: 0.010393177897655037
reward sum -921.0424693769096
l/s -0.7219723988215228
t 307.9803466796875
-----------
-----------
l: 0.0
q: 0.0
r: -0.04524524955182496
reward sum -955.6884862473893
l/s -0.6564927101784984
t 306.48138523101807
-----------
-----------
l: 0.0
q: 0.0
r: -0.068536194237931
reward sum -1043.5577694646477
l/s -0.523802591352453
t 309.77017879486084
-----------
-----------
l: 0.0
q: 0.0
r: -0.054590227893904775
reward sum -1061.9703889309176
l/s -0.5314759036144578
t 307.94334411621094
-----------
-----------
l: 0.0
q: 0.0
r: -0.13622875007075397
reward sum -1017.8404575604362
l/s -0.7999129425420778
t 306.82947635650635
-----------
-----------
l: 0.0
q: 0.0
r: -0.15872430198381693
reward sum -1004.2701978315299
l/s -0.5199700822737472
t 305.5985450744629
-----------
-----------
l: 0.0
q: 0.0
r: -0.02098078448948426
reward sum -983.6576903974182
l/s -0.47731731240804315
t 307.80930519104004
-----------
