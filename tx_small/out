nohup: ignoring input
2022-06-05 11:37:43.994492: I tensorflow/core/tpu/tpu_api_dlsym_initializer.cc:116] Libtpu path is: libtpu.so
Missing key: 'TWIST' in 'tpu-env' (yaml) instance metadata.
2022-06-05 11:37:45.642962: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA
To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.
2022-06-05 11:37:49.167162: I tensorflow/compiler/xla/service/service.cc:170] XLA service 0x5f39980 initialized for platform TPU (this does not guarantee that XLA will be used). Devices:
2022-06-05 11:37:49.167210: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (0): TPU, 2a886c8
2022-06-05 11:37:49.167218: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (1): TPU, 2a886c8
2022-06-05 11:37:49.167225: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (2): TPU, 2a886c8
2022-06-05 11:37:49.167230: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (3): TPU, 2a886c8
2022-06-05 11:37:49.167236: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (4): TPU, 2a886c8
2022-06-05 11:37:49.167241: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (5): TPU, 2a886c8
2022-06-05 11:37:49.167247: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (6): TPU, 2a886c8
2022-06-05 11:37:49.167252: I tensorflow/compiler/xla/service/service.cc:178]   StreamExecutor device (7): TPU, 2a886c8
WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.
2022-06-05 11:37:56.267249: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:263] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.
2022-06-05 11:37:56.288303: I tensorflow/compiler/jit/xla_compilation_cache.cc:478] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.
2022-06-05 11:37:56.303206: W tensorflow/compiler/tf2xla/kernels/random_ops.cc:57] Warning: Using tf.random.uniform with XLA compilation will ignore seeds; consider using tf.random.stateless_uniform instead if reproducible behavior is desired. RandomUniform
Model: "model"
__________________________________________________________________________________________________
 Layer (type)                   Output Shape         Param #     Connected to                     
==================================================================================================
 input_1 (InputLayer)           [(None, 550, 6)]     0           []                               
                                                                                                  
 dense (Dense)                  (None, 550, 16)      112         ['input_1[0][0]']                
                                                                                                  
 dense_1 (Dense)                (None, 550, 16)      272         ['dense[0][0]']                  
                                                                                                  
 conv1d (Conv1D)                (None, 550, 64)      3136        ['dense_1[0][0]']                
                                                                                                  
 concatenate (Concatenate)      (None, 550, 80)      0           ['conv1d[0][0]',                 
                                                                  'dense_1[0][0]']                
                                                                                                  
 dense_2 (Dense)                (None, 550, 32)      2592        ['concatenate[0][0]']            
                                                                                                  
 conv1d_1 (Conv1D)              (None, 550, 512)     344576      ['dense_2[0][0]']                
                                                                                                  
 concatenate_1 (Concatenate)    (None, 550, 544)     0           ['conv1d_1[0][0]',               
                                                                  'dense_2[0][0]']                
                                                                                                  
 dense_3 (Dense)                (None, 550, 512)     279040      ['concatenate_1[0][0]']          
                                                                                                  
 dense_4 (Dense)                (None, 550, 256)     131328      ['dense_3[0][0]']                
                                                                                                  
 layer_normalization (LayerNorm  (None, 550, 256)    512         ['dense_4[0][0]']                
 alization)                                                                                       
                                                                                                  
 positions (Positions)          (None, 550, 256)     0           ['layer_normalization[0][0]']    
                                                                                                  
 transformer_block (Transformer  (None, 550, 256)    2236160     ['positions[0][0]',              
 Block)                                                           'positions[0][0]']              
                                                                                                  
 transformer_block_1 (Transform  (None, 550, 256)    2236160     ['transformer_block[0][0]',      
 erBlock)                                                         'transformer_block[0][0]']      
                                                                                                  
 transformer_block_2 (Transform  (None, 550, 256)    2236160     ['transformer_block_1[0][0]',    
 erBlock)                                                         'transformer_block_1[0][0]']    
                                                                                                  
 transformer_block_3 (Transform  (None, 550, 256)    2236160     ['transformer_block_2[0][0]',    
 erBlock)                                                         'transformer_block_2[0][0]']    
                                                                                                  
 lambda (Lambda)                (None, 256)          0           ['transformer_block_3[0][0]']    
                                                                                                  
 reshape (Reshape)              (None, 1, 256)       0           ['lambda[0][0]']                 
                                                                                                  
 transformer_block_4 (Transform  (None, 1, 256)      2236160     ['reshape[0][0]',                
 erBlock)                                                         'transformer_block_3[0][0]']    
                                                                                                  
 input_2 (InputLayer)           [(None, 2)]          0           []                               
                                                                                                  
 flatten (Flatten)              (None, 256)          0           ['transformer_block_4[0][0]']    
                                                                                                  
 concatenate_2 (Concatenate)    (None, 258)          0           ['input_2[0][0]',                
                                                                  'flatten[0][0]']                
                                                                                                  
 dense_15 (Dense)               (None, 512)          132608      ['concatenate_2[0][0]']          
                                                                                                  
 leaky_re_lu (LeakyReLU)        (None, 512)          0           ['dense_15[0][0]']               
                                                                                                  
 dense_16 (Dense)               (None, 512)          262656      ['leaky_re_lu[0][0]']            
                                                                                                  
 leaky_re_lu_1 (LeakyReLU)      (None, 512)          0           ['dense_16[0][0]']               
                                                                                                  
 dense_17 (Dense)               (None, 512)          262656      ['leaky_re_lu_1[0][0]']          
                                                                                                  
 leaky_re_lu_2 (LeakyReLU)      (None, 512)          0           ['dense_17[0][0]']               
                                                                                                  
 dense_18 (Dense)               (None, 3)            1536        ['leaky_re_lu_2[0][0]']          
                                                                                                  
==================================================================================================
Total params: 12,601,824
Trainable params: 12,601,824
Non-trainable params: 0
__________________________________________________________________________________________________
loading weights...
warmup...
2022-06-05 11:39:20.484106: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:13793478483563359504
2022-06-05 11:39:20.531175: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:39:20.585496: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:39:20.666815: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(16750561978805250095), session_name()
2022-06-05 11:39:23.137213: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 16750561978805250095 with session name  took 2.470243708s and succeeded
2022-06-05 11:39:23.148546: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(16750561978805250095), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_13793478483563359504", property.function_library_fingerprint = 7955759564443233598, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 11:39:23.148594: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 16750561978805250095 with session_name  cache is 1 entries (16463402 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.0
q: 0.0
reward sum -282.44575583645536
l/s -0.5910179184140297
t 72.90639877319336
-----------
/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py:3474: RuntimeWarning: Mean of empty slice.
  return _methods._mean(a, axis=axis, dtype=dtype,
/usr/local/lib/python3.8/dist-packages/numpy/core/_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars
  ret = ret.dtype.type(ret / rcount)
training...
2022-06-05 11:46:15.923488: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:6429849198563833857
2022-06-05 11:46:15.975698: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:46:16.036455: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:46:16.128421: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(5177847321016326691), session_name()
2022-06-05 11:46:18.703763: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 5177847321016326691 with session name  took 2.575238952s and succeeded
2022-06-05 11:46:18.712154: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(5177847321016326691), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_6429849198563833857", property.function_library_fingerprint = 5637507469714844412, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 11:46:18.712200: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 5177847321016326691 with session_name  cache is 2 entries (31777495 bytes),  marked for eviction 0 entries (0 bytes).
2022-06-05 11:46:27.634063: I tensorflow/core/tpu/graph_rewrite/encapsulate_tpu_computations_pass.cc:254] Subgraph fingerprint:5012925305446257455
2022-06-05 11:46:28.057345: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:46:28.477895: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:903] model_pruner failed: INVALID_ARGUMENT: Graph does not contain terminal node StatefulPartitionedCall.
2022-06-05 11:46:29.079837: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:435] TPU host compilation cache miss: cache_key(6743992970580505920), session_name()
2022-06-05 11:46:46.097744: I tensorflow/core/tpu/kernels/tpu_compile_op_common.cc:193] Compilation of 6743992970580505920 with session name  took 17.017807261s and succeeded
2022-06-05 11:46:46.144700: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:468] TPU host compilation cache: compilation complete for cache_key(6743992970580505920), session_name(), subgraph_key(std::string(property.function_name) = "cluster_tpu_function_5012925305446257455", property.function_library_fingerprint = 14173708073217953145, property.mlir_module_fingerprint = 0, property.num_replicas = 8, topology.chip_bounds().x = 2, topology.chip_bounds().y = 2, topology.chip_bounds().z = 1, topology.wrap().x = false, topology.wrap().y = false, topology.wrap().z = false, topology.MissingChipCount() = 0, std::string(property.shapes_prefix) = "", property.guaranteed_constants_size = 0, embedding_partitions_fingerprint = "1688352644216761960")
2022-06-05 11:46:46.144761: I tensorflow/core/tpu/kernels/tpu_compilation_cache_interface.cc:534] After adding entry for key 6743992970580505920 with session_name  cache is 3 entries (154737945 bytes),  marked for eviction 0 entries (0 bytes).
-----------
l: 0.15214647394791245
q: 0.08174875439796597
reward sum -47.75898640068229
l/s -0.6102269378131447
t 280.31561374664307
-----------
-----------
l: 0.16148789014693324
q: 0.08320930388781217
reward sum -43.82539631037434
l/s -0.587054198258916
t 281.7290782928467
-----------
-----------
l: 0.16255862642820185
q: 0.0771082792855375
reward sum -68.32167028019066
l/s -0.6490593342981187
t 281.16512298583984
-----------
-----------
l: 0.16497193791761205
q: 0.0765840432589309
reward sum -81.45110554010738
l/s -0.47161272627537026
t 281.8950891494751
-----------
-----------
l: 0.16301591856801487
q: 0.06957350252795133
reward sum -69.10408646267975
l/s -0.38817431368784794
t 279.3401002883911
-----------
-----------
l: 0.16172509647526226
q: 0.06709125060723028
reward sum -9.813027010536931
l/s -0.298050723118843
t 284.3545198440552
-----------
-----------
l: 0.15823789790354587
q: 0.06282960718135246
reward sum 3.295218098388489
l/s -0.04912111726462798
t 280.55903911590576
-----------
-----------
l: 0.15962939961561254
q: 0.05774075864010828
reward sum -14.233009684881143
l/s -0.18836944127708097
t 279.6997308731079
-----------
